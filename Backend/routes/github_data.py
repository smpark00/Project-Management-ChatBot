import os
import csv
import requests
import zipfile
from fastapi import FastAPI, HTTPException, Query
from pathlib import Path
from fastapi import APIRouter
from dotenv import load_dotenv

router = APIRouter()

# .env íŒŒì¼ ë¡œë“œ
load_dotenv("../../.env")

# ì €ì¥ ê²½ë¡œ ì„¤ì •
BASE_DIRECTORY = Path(os.path.abspath(os.path.join(os.path.dirname(__file__), "../storage")))
BASE_DIRECTORY.mkdir(parents=True, exist_ok=True)

# GitHub Personal Access Token (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
HEADERS = {"Authorization": f"token {GITHUB_TOKEN}"} if GITHUB_TOKEN else {}


def fetch_all_data(url, params=None):
    """í˜ì´ì§•ì„ ì²˜ë¦¬í•˜ì—¬ ëª¨ë“  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê¸°"""
    all_data = []
    page = 1
    while True:
        if params is None:
            params = {}
        params.update({"per_page": 100, "page": page})  # í˜ì´ì§€ ë²ˆí˜¸ ì¶”ê°€

        response = requests.get(url, headers=HEADERS, params=params)
        if response.status_code == 200:
            data = response.json()
            if not data:  # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                break
            all_data.extend(data)
            page += 1
        else:
            print(f"Error fetching data from {url}: {response.status_code}")
            break
    return all_data


def get_project_details(owner, repo):
    """íŠ¹ì • í”„ë¡œì íŠ¸ì˜ ìƒì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    base_url = f"https://api.github.com/repos/{owner}/{repo}"

    # ë¦¬í¬ì§€í† ë¦¬ ê¸°ë³¸ ì •ë³´
    repo_info = requests.get(base_url, headers=HEADERS).json()

    # ëª¨ë“  ì»¤ë°‹ ë°ì´í„°
    commits = fetch_all_data(f"{base_url}/commits")

    # ëª¨ë“  Pull Requests ë°ì´í„°
    pull_requests = fetch_all_data(f"{base_url}/pulls", params={"state": "all"})

    # ëª¨ë“  ì´ìŠˆ ë°ì´í„°
    issues = fetch_all_data(f"{base_url}/issues")

    return {
        "repo_info": repo_info,
        "commits": commits,
        "pull_requests": pull_requests,
        "issues": issues
    }


def save_to_csv(data, repo_name):
    """ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    repo_info = data["repo_info"]

    # ğŸ“Œ í”„ë¡œì íŠ¸ë§ˆë‹¤ ë””ë ‰í† ë¦¬ ìƒì„± í›„, ê·¸ ì•ˆì— csv ë””ë ‰í† ë¦¬ ìƒì„±
    project_path = BASE_DIRECTORY / repo_name / "csv"
    project_path.mkdir(parents=True, exist_ok=True)

    # í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ ì €ì¥
    with open(project_path / f"{repo_name}_info.csv", "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["ID", "Name", "Description", "Stars", "Forks", "Language", "Last Updated", "Owner"])
        writer.writerow([
            repo_info.get("id", ""),
            repo_info.get("name", ""),
            repo_info.get("description", ""),
            repo_info.get("stargazers_count", 0),
            repo_info.get("forks_count", 0),
            repo_info.get("language", ""),
            repo_info.get("updated_at", ""),
            repo_info.get("owner", {}).get("login", "")
        ])

    # ì»¤ë°‹ ì •ë³´ ì €ì¥
    with open(project_path / f"{repo_name}_commits.csv", "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["ID", "Author", "Date", "Message"])
        for commit in data["commits"]:
            author_login = commit.get("author", {}).get("login") if commit.get("author") else "Unknown"
            writer.writerow([
                commit.get("sha", ""),
                author_login,
                commit["commit"]["author"]["date"],
                commit["commit"].get("message", "")
            ])

    # Pull Requests ì •ë³´ ì €ì¥
    with open(project_path / f"{repo_name}_pull_requests.csv", "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["ID", "Title", "Author", "State", "Created At", "Merged At", "Closed At"])
        for pr in data["pull_requests"]:
            writer.writerow([
                pr.get("id", ""),
                pr.get("title", ""),
                pr["user"]["login"],
                pr.get("state", ""),
                pr.get("created_at", ""),
                pr.get("merged_at", ""),
                pr.get("closed_at", "")
            ])

    # ì´ìŠˆ ì •ë³´ ì €ì¥
    with open(project_path / f"{repo_name}_issues.csv", "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["ID", "Title", "State", "Created At", "Closed At"])
        for issue in data["issues"]:
            writer.writerow([
                issue.get("id", ""),
                issue.get("title", ""),
                issue.get("state", ""),
                issue.get("created_at", ""),
                issue.get("closed_at", "")
            ])


@router.post("/download")
async def download_repository(repo_url: str = Query(...)):
    """
    GitHub ì €ì¥ì†Œë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œì»¬ì— ì €ì¥í•œ í›„, ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
    """
    try:
        if not repo_url.startswith("https://github.com/"):
            raise HTTPException(status_code=400, detail="Invalid GitHub URL")

        repo_parts = repo_url.replace("https://github.com/", "").split("/")
        if len(repo_parts) < 2:
            raise HTTPException(status_code=400, detail="Invalid GitHub repository format")
        owner, repo = repo_parts[0], repo_parts[1]
        repo = repo.replace(".git", "")

        # GitHub APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        repo_data = get_project_details(owner, repo)

        # CSV ì €ì¥
        save_to_csv(repo_data, repo)

        return {
            "message": "Repository data successfully saved.",
            "repository_name": repo,
            "csv_directory": str(BASE_DIRECTORY / repo / "csv"),
            "csv_files": [str(file) for file in (BASE_DIRECTORY / repo / "csv").glob("*.csv")]
        }

    except HTTPException as e:
        raise e
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {repr(e)}")
